Class PokerEnv {...}
% A class representing the poker env, it's implementation
% will not be shown in this pseudo-code

Struct StategyInfo {
    float value;
    string action;
}

Struct NodeInfo {
    % you should store an hash key of this env intead of
    % the full PokerEnv, we are doing this for readability
    PokerEnv env
    float regret
    Map<PokerEnv, strategys> strategys
}

nodes = {}

void runOnce(env, proba):
    currentNode = nodes[env]

    if (env.isOver()):
        currentNode.regret = env.reward * proba
        return

    actions = env.getAvailableActions()
    leadingNodes = {}
    total = 0

    % explore and compute values of the leading nodes
    FOR action in actions:
        copy = env.copy()
        copy.play(action)
        if (!currentNode.strategys[copy]):
            currentNode.strategys[copy] = {
                value: 1 / actions.size
                action: action
            }
        runOnce(copy, currentNode.strategys[copy].value * proba)
        leadingNodes.append(nodes[copy])

    sumNegativeRegret = 0
    sumPositiveRegret = 0
    for FOR node in leadingNodes:
        regret = -node.regret
        if (regret > 0):
            sumPositiveRegret += regret;
        else:
            sumNegativeRegret += regret;

    % update strategies
    FOR node IN leadingNodes:
        regret = -node.regret
        if (sumPositiveRegret > 0):
            currentNode.strategys[node.env].value = regret > 0 ? regret / sumPositiveRegret : 0;
        else if (sumNegativeRegret != 0):
            currNode.strategys[node.env].value = regret == 0 ? 1.0f : 1 - abs(regret / sumNegativeRegret);
        else:
            currNode.strategys[node.env].value = 1;

    % weight the stratgies so it sum up to 1
    float totalStrategy = 0
    FOR node in leadingNodes:
        totalStrategy += currentNode.strategys[node.env].value
    FOR node in leadingNodes:
        currNode.strategys[node.env].value /= totalStrategy;

    % compute the regret of this node
    FOR node in leadingNodes:
        currentNode.regret += proba * -node.regret * currentNode.strategies[node.env].value

env = PokerEnv(public_cards,private_cards,...)
% Initial environemnt of which you want the CFR Value
% It takes all the necessary information to create a moment in the game.
for _ in NB_ITERATION:
    env.generateRandomCardsFor2ndPlayer()
    runOnce(env, 1)

% CFR values are in nodes[env].strategies
FOR strategy in nodes[env].strategies:
    print("Action {strategy.action} -> strategy.value")