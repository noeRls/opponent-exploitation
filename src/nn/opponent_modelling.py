from src.environement.Agent import Agent
from src.environement.Environment import Environment
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
from .NN import NN

class OpponentModellingNN(NN):
    def get_input_size(self):
        game_history_size = self.game_info.available_action_size * self.game_info.player_max_action_per_game * 4
        # *4 -> own_action + opponent_action + opponent equilibrium private + opponent equilibrium public
        return game_history_size + self.game_info.game_outcome_size + self.modelling_size

    def _create_model(self):
        input_size = self.get_input_size()
        self.model = keras.Sequential([
            layers.Input(shape=(input_size,)),
            layers.Dense(10),
            layers.Dense(self.modelling_size),
        ])

def create_opponent_modelling_input(env: Environment, agent: Agent, opponent_model: np.ndarray):
    opponent = env.get_opponent(agent)
    return np.concatenate((
        agent.actions_np.flatten(),
        opponent.actions_np.flatten(),
        opponent.private_equilibrium.flatten() if opponent.revealed else np.zeros(len(opponent.private_equilibrium.flatten())),
        opponent.public_equilibrium.flatten(),
        env.game_outcome_array_for_agent(agent),
        opponent_model,
    ))
