from src.environement.Agent import Agent
from src.environement.Environment import Environment
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
from .NN import NN

class OpponentModellingNN(NN):
    def get_input_size(self):
        game_history_size = self.game_info.available_action_size * self.game_info.player_max_action_per_game * 4
        # *4 -> own_action + opponent_action + opponent equilibrium private + opponent equilibrium public
        return game_history_size + self.game_info.game_outcome_size + self.modelling_size

    def _create_model(self):
        input_size = self.get_input_size()
        self.model = keras.Sequential(
            [layers.Dense(input_size)],
            [layers.Dense(10)],
            [layers.Dense(self.modelling_size)],
        )

def create_opponent_modelling_input(env: Environment, agent: Agent, opponent_model: np.ndarray):
    opponent = env.get_opponent(agent)
    return np.concatenate((
        agent.actions_np,
        opponent.actions_np,
        opponent.private_equilibrium if opponent.revealed else np.zeros(len(opponent.private_equilibrium)),
        opponent.public_equilibrium,
        env.game_outcome_array_for_agent(agent),
        opponent_model,
    ))
