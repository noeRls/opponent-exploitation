from __future__ import annotations
from src.utils.plot import save_plot
import shap
from tensorflow import keras
from src.environement.State import State
import numpy as np
from typing import List
import json

import tensorflow as tf

tfloaded = False
def loadtf():
    global tfloaded
    if tfloaded:
        return
    tfloaded = True
    gpus = tf.config.experimental.list_physical_devices('GPU')
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
    if len(gpus) > 0:
        print('USING GPU')
        tf.config.experimental.set_virtual_device_configuration(
            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])
    else:
        print('NOT USING GPU')


class NNGameInfo():
    available_action_size: int
    player_max_action_per_game: int
    game_outcome_size: int

    def __init__(self, state: State) -> None:
        self.available_action_size = state.actions_number
        self.player_max_action_per_game = state.get_max_action_agent()
        self.game_outcome_size = state.game_outcome_size


def shape_to_num_elements(shape):
    total = None
    for num in shape:
        if total is None:
            total = num
        else:
            total *= num
    return total


class HiddenLayersParams():
    size: int
    activation: keras.activations

    def __init__(self, size: int, activation: keras.activations) -> None:
        loadtf()
        self.size = size
        self.activation = activation

    def toJSON(self) -> str:
        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)

    @staticmethod
    def fromJSON(data) -> HiddenLayersParams:
        return HiddenLayersParams(
            data["size"],
            data["activation"]
        )


class NNParams():
    hidden_layers: List[HiddenLayersParams] = []
    modelling_size: int

    def __init__(self, modelling_size: int, hidden_layers: List[HiddenLayersParams]) -> None:
        self.hidden_layers = hidden_layers
        self.modelling_size = modelling_size

    def toJSON(self) -> str:
        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)

    @staticmethod
    def fromJSON(data) -> NNParams:
        layers: List[HiddenLayersParams] = []
        for layer in data["hidden_layers"]:
            layers.append(HiddenLayersParams.fromJSON(layer))
        return NNParams(data["modelling_size"], layers)


class DumbNNParams(NNParams):
    def __init__(self):
        super().__init__(1, [])

class NN():
    store_history = False
    history_len = 10000
    model: keras.Sequential
    game_info: NNGameInfo
    samples_input: List[np.ndarray]
    params: NNParams

    def __init__(self, game_info: NNGameInfo, params: NNParams) -> None:
        self.game_info = game_info
        self.samples_input = []
        self.params = params
        self._create_model()

    def get_input_size(self):
        raise NotImplementedError()

    def _get_hidden_layers(self) -> List[keras.layers.Layer]:
        result: List[keras.layers.Layer] = []
        for layer in self.params.hidden_layers:
            result.append(keras.layers.Dense(layer.size, activation=layer.activation))
        return result

    def _create_model(self):
        raise NotImplementedError()

    def set_weights_from_array(self, weights: np.ndarray):
        offset = 0
        for layer in self.model.layers:
            shape = layer.get_weights()[0].shape

            weights_size = layer.get_weights()[0].size
            new_weights = np.reshape(
                weights[offset:offset + weights_size], shape)
            offset += weights_size

            bias_size = shape[-1]
            new_bias = weights[offset:offset + bias_size]
            offset += bias_size

            layer.set_weights([new_weights, new_bias])

    def get_total_weights_size(self):
        weights = self.model.weights
        total = 0
        for w in weights:
            total += w.get_shape().num_elements()
            total += w.get_shape()[-1]  # bias
        return total

    def predict(self, nn_input: np.ndarray):
        if self.store_history:
            self.samples_input.append(nn_input)
            self.samples_input = self.samples_input[-self.history_len:]
        return self.model.predict_on_batch(np.array([nn_input]))[0]

    def copy_model(self, to_copy: NN):
        self.model = keras.models.clone_model(to_copy.model)

    def save(self, path: str):
        self.model.save(f'{path}-model')
        self.model.save_weights(f'{path}-weights')
        with open(f'{path}-params', 'w+') as file:
            file.write(self.params.toJSON())

    def load(self, path: str):
        self.model = keras.models.load_model(f'{path}-model')
        self.model.load_weights(f'{path}-weights')
        with open(f'{path}-params', 'r') as file:
            data = json.load(file)
            self.params = NNParams.fromJSON(data)

    def get_input_labels(self) -> List[str]:
        raise NotImplementedError()

    def get_output_labels(self) -> List[str]:
        raise NotImplementedError()

    def summary(self, save_id: str):
        X = np.array(self.samples_input)
        np.random.shuffle(X)
        X = X[:30]
        X_test = X
        explainer = shap.KernelExplainer(
            model=self.model.predict, data=X, link="identity")
        shap_values = explainer.shap_values(np.array(X_test))
        input_labels = self.get_input_labels()
        if len(input_labels) != self.get_input_size():
            raise Exception('Invalid input labels len')
        output_labels = self.get_output_labels()
        if len(output_labels) != len(shap_values):
            raise Exception('Invalid ouput labels len')
        for i in range(len(output_labels)):
            shap.summary_plot(shap_values[i], input_labels, show=False)
            save_plot(save_id, f'{output_labels[i]}-input-impact', True)
