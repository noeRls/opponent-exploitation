from typing import List
from src.environement.Environment import Environment
from src.environement.Strategy import Strategy

class PlayAgainstResult():
    r1: int
    r2: int
    r1_history: List[int]
    r2_history: List[int]

    def __init__(self) -> None:
        self.r1 = 0
        self.r2 = 0
        self.r1_history = []
        self.r2_history = []

def play_against(env: Environment, strategy1: Strategy,
                 strategy2: Strategy, nb_games=10, debug=False, history=None) -> PlayAgainstResult:
    strategy1.lock.acquire(blocking=True)
    strategy2.lock.acquire(blocking=True)
    strategy1.set_env(env)
    strategy2.set_env(env)
    strategy1.set_agent(env.agent1)
    strategy2.set_agent(env.agent2)
    result = PlayAgainstResult()
    states = [env.generate_random_starting_state() for _ in range(nb_games)]
    for step in range(2):
        strategy1.reset()
        strategy2.reset()
        env.next_game(step == 0)
        for i in range(nb_games):
            env.set_starting_state(states[i], step == 0)
            while not env.game_ended:
                strategy = strategy1 if env.is_p1_turn() else strategy2
                action = strategy.get_play()
                env.play(action)
                if debug:
                    print(f"{strategy.get_name()} playing {action}")
            result.r1 += env.agent1.reward
            result.r2 += env.agent2.reward
            if history and step == 0:
                result.r1_history.append(result.r1)
                result.r2_history.append(result.r2)
            if debug:
                print(
                    f"{strategy1.get_name()}={env.agent1.reward} {strategy2.get_name()}={env.agent2.reward}")
                print(f'r1={result.r1} r2={result.r2}')
            strategy1.on_game_end()
            strategy2.on_game_end()
            env.next_game(not env.p1_start_this_game())
    strategy1.lock.release()
    strategy2.lock.release()
    return result
