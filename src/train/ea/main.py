from src.environement.Kuhn.strategy.always_bet import AlwaysBetStrategy
from src.environement.Kuhn.strategy.always_fold import AlwaysFoldStrategy
from src.environement.Environment import Environment
from src.environement.Kuhn.strategy.best_response import KuhnBestResponseStrategy
from src.environement.Kuhn.strategy.human_strategy import HumanStrategy
from src.environement.Kuhn.strategy.equilibrium import EquilibriumStrategy
from src.nn.NN import NN
from src.constants import SAVE_MODEL_PATH
from src.train.ea.NNIndividual import NNIndividual
from src.nn.NNStrategy import NNStrategy
from src.train.ea.Population import Population, TrainingIndividual
from src.train.ea.Individual import Individual
from src.environement.Strategy import Strategy
from .play_against import play_against
from src.environement.Kuhn.strategy.all_strategy import ALL_KUHN_STRATEGY
from src.environement.Kuhn.KuhnEnv import KuhnEnv
from typing import List
from .Individual import Individual
import matplotlib.pyplot as plt

MODEL_SIZE = 5


def train():
    env = KuhnEnv()
    teaching_individuals: List[Individual] = []
    for S in ALL_KUHN_STRATEGY:
        teaching_individuals.append(Individual(S()))
    TRAINING_NB = 10
    NEW_INDIVIDUAL_PER_ITERATION = 7
    MUTATION_RATE = 0.1
    ITERATION = 50
    training_individuals: List[TrainingIndividual] = [NNIndividual(
        NNStrategy(env, MODEL_SIZE)) for _ in range(TRAINING_NB)]
    population = Population(
        training_individuals=training_individuals,
        new_individual_per_iteration=NEW_INDIVIDUAL_PER_ITERATION,
        mutation_rate=MUTATION_RATE,
        teaching_set=teaching_individuals
    )
    for iteration_nb in range(ITERATION):
        print(f'ITERATION {iteration_nb + 1}')
        population.process_iteration(env)
    individual = population.get_best_individual()
    s: NNStrategy = individual.startegy
    s.save(SAVE_MODEL_PATH)


def analyze(save_id: int,
    nn_summary=False,
    best_response=False,
    reward_over_time=False
):
    env = KuhnEnv()
    nn_strategy = NNStrategy(env, MODEL_SIZE)
    nn_strategy.load(SAVE_MODEL_PATH, save_id)
    NN.store_history = True
    if best_response:
        best_response_report(env, nn_strategy)
    if nn_summary:
        play_against(env, nn_strategy, EquilibriumStrategy(), 100)
        nn_strategy.descision_making_nn.summary()
    if reward_over_time:
        plot_reward_over_time(env, nn_strategy, AlwaysBetStrategy())
        plot_reward_over_time(env, nn_strategy, AlwaysFoldStrategy())
        plot_reward_over_time(env, nn_strategy, EquilibriumStrategy())
        plot_reward_over_time(env, nn_strategy, KuhnBestResponseStrategy())
        plt.show()

def best_response_report(env: KuhnEnv, strategy: Strategy):
    best_response_strategy = KuhnBestResponseStrategy()
    result = play_against(env, strategy, best_response_strategy, 50)
    print(f"best_reponse={result.r2} tested_strategy={result.r1}")

def plot_reward_over_time(env: Environment, strategy_plot: Strategy, opponent: Strategy):
    result = play_against(env, strategy_plot, opponent, nb_games=100, history=True)
    fig, ax = plt.subplots()
    ax.plot([i for i in range(len(result.r1_history))], result.r1_history)
    ax.set(xlabel="Game", ylabel="Reward", title=f"{strategy_plot.get_name()} reward against {opponent.get_name()} over time")

def play_with_human(save_id: int, nb_games=5):
    env = KuhnEnv()
    nn_strategy = NNStrategy(env, MODEL_SIZE)
    nn_strategy.load(SAVE_MODEL_PATH, save_id)
    human_strategy = HumanStrategy()
    play_against(env, nn_strategy, human_strategy, nb_games, debug=True)

def main():
    # train()
    analyze(1308653041264, reward_over_time=True, best_response=True, nn_summary=True)
