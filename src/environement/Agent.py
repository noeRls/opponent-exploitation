import numpy as np
from Environment import Environment

class Agent():
    __env: Environment
    __step: int
    private_equilibrium: np.ndarray
    public_equilibrium: np.ndarray
    actions: np.ndarray
    revealed: bool

    def __init__(self, env: Environment):
        self.__env = env
        self.reset()

    def __compute_public_equilibrium(self):
        raise NotImplementedError()

    def __compute_private_equilibrium(self):
        raise NotImplementedError()

    def compute_equilibrium(self):
        self.private_equilibrium[self.__step] = self.__compute_private_equilibrium()
        self.public_equilibrium[self.__step] = self.__compute_public_equilibrium()

    def play(self, action):
        self.compute_equilibrium()
        self.actions[self.__step] = action
        self.__step += 1

    def reset(self):
        self.__step = 0
        self.private_equilibrium = np.zeros((self.__env.get_max_action_agent(), self.__env.actions_number))
        self.public_equilibrium = np.zeros((self.__env.get_max_action_agent(), self.__env.actions_number))
        self.actions = np.zeros((self.__env.get_max_action_agent()))
        self.revealed = True
