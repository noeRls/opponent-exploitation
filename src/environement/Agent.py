import numpy as np
from .State import State


class Agent():
    _state: State
    _step: int
    reward: int
    private_equilibrium: np.ndarray
    public_equilibrium: np.ndarray
    actions_np: np.ndarray
    actions: list
    revealed: bool
    _start: bool

    def __init__(self, env: State):
        self._state = env
        self.reset(True)

    def compute_public_equilibrium(self):
        raise NotImplementedError()

    def compute_private_equilibrium(self):
        raise NotImplementedError()

    def compute_equilibrium(self) -> np.ndarray:
        self.private_equilibrium[self._step] = self.compute_private_equilibrium(
        )
        self.public_equilibrium[self._step] = self.compute_public_equilibrium(
        )
        return self.private_equilibrium[self._step]

    def play(self, action):
        self.compute_equilibrium()
        self.actions_np[self._step][action.value] = 1
        self.actions.append(action)
        self._step += 1

    def reset(self, will_start):
        self._step = 0
        self.reward = 0
        self._start = will_start
        self.private_equilibrium = np.zeros(
            (self._state.get_max_action_agent(), self._state.actions_number))
        self.public_equilibrium = np.zeros(
            (self._state.get_max_action_agent(), self._state.actions_number))
        self.actions_np = np.zeros(
            (self._state.get_max_action_agent(), self._state.actions_number))
        self.actions = []
        self.revealed = False
