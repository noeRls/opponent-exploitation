from src.environement.Environment import Environment
from ..Strategy import Strategy
import numpy as np

class CloseEquilibriumStrategy(Strategy):
    diff: np.array

    def __init__(self, diff: np.array = None) -> None:
        super().__init__()
        self.diff = None
        if diff is not None:
            self.diff = diff

    def set_env(self, env: Environment):
        super().set_env(env)
        if self.diff is None:
            self.diff = np.random.uniform(
                low=-0.2, high=0.2, size=(self.env.state.actions_number,))

    def get_name(self):
        return f"CloseEquilibrium-{id(self)}"

    def get_play(self):
        equilibrium = self.agent.compute_equilibrium()
        equilibrium = equilibrium - self.diff
        equilibrium = np.clip(equilibrium, 0, np.amax(equilibrium))
        equilibrium = equilibrium/equilibrium.sum(axis=0,keepdims=1)
        action = np.random.choice(
            [i for i in range(len(equilibrium))], p=equilibrium)
        action = self.env.transform_action_to_enum(action)
        return self._action_or_default(action)

    def copy(self):
        return CloseEquilibriumStrategy(self.diff)
